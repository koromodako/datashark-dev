#!/usr/bin/env python3
'''
Datashark repo management script
'''
import sys
from shutil import which, rmtree
from logging import basicConfig, getLogger
from pathlib import Path
from argparse import ArgumentParser
from subprocess import run, CalledProcessError
from configparser import ConfigParser


try:
    from rich.logging import RichHandler

    RICH_HANDLER = RichHandler(
        omit_repeated_times=False,
        rich_tracebacks=True,
        markup=False,
    )
    RICH_HANDLER.setLevel('DEBUG')
    basicConfig(
        format='%(message)s',
        datefmt='[%Y-%m-%dT%H:%M:%S]',
        level='DEBUG',
        handlers=[RICH_HANDLER],
    )
except ImportError:
    basicConfig(
        format='(%(name)s)[%(levelname)7s]: %(message)s',
        level='DEBUG',
    )


HERE = Path(__file__).parent.resolve()
VENV = HERE / 'venv'
PIP = VENV / 'bin' / 'pip'
REPO = which('repo')
RELEASE = HERE / 'release'
RELEASE_SDIST = RELEASE / 'sdist'
RELEASE_WHEEL = RELEASE / 'wheel'
LOGGER = getLogger('manage')
LOGGER.setLevel('INFO')


REQUIREMENTS = [
    'pip',
    'rich',
    'wheel',
    'build',
    'black',
    'pylint',
    'setuptools',
    'ruamel.yaml',
]


def mkdir(*directories):
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)


def confirm(question):
    """YES/NO question confirmation"""
    answer = input(f"{question} [y/N]: ").lower()
    return answer and 'yes'.startswith(answer)


def enumerate_prod_repositories():
    """List production repositories"""
    proc = run_subproc(
        [REPO, 'list', '-g', 'prod', '--path-only'],
        text=True,
        capture_output=True,
    )
    for line in proc.stdout.split('\n'):
        line = line.strip()
        if line:
            yield HERE / line


def run_subproc(args, **kwargs):
    """Start a subprocess and wait for it to finish"""
    LOGGER.debug("subprocess started: %s", args)
    if 'check' in kwargs:
        del kwargs['check']
    try:
        return run(args, check=True, **kwargs)
    except KeyboardInterrupt:
        return None


def merge_conf(dst, src):
    """Merge configuration files"""
    for key, value in src.items():
        # add non existant value to dict
        if key not in dst:
            dst[key] = value
            continue
        # merge dicts
        if isinstance(value, dict):
            if isinstance(dst[key], dict):
                merge_conf(dst[key], value)
                continue
            LOGGER.warning(
                "cannot merge '%s', inconsistent types (%s != %s)",
                key,
                type(value),
                type(dst[key]),
            )
        # merge lists
        if isinstance(value, list):
            if isinstance(dst[key], list):
                dst[key] += value
                continue
            LOGGER.warning(
                "cannot merge '%s', inconsistent types (%s != %s)",
                key,
                type(value),
                type(dst[key]),
            )
        LOGGER.warning("merge cannot override existing key '%s'", key)


def init_cmd(_):
    """Initialize virtual environment"""
    if VENV.is_dir() and not confirm("Do you want to perform the operation?"):
        return
    run_subproc(['python3', '-m', 'venv', str(VENV)])
    run_subproc([str(PIP), 'install', '-U'] + REQUIREMENTS)


def fmt_cmd(_):
    """Run black on production repositories"""
    fmt_prog = str(VENV / 'bin' / 'black')
    for repo in enumerate_prod_repositories():
        run_subproc([fmt_prog, str(repo)])


def lint_cmd(_):
    """Run pylint on production repositories"""
    lint_prog = str(VENV / 'bin' / 'pylint')
    for repo in enumerate_prod_repositories():
        try:
            run_subproc([lint_prog, str(repo)])
        except CalledProcessError as exc:
            LOGGER.warning(
                "linter exited with failure code: %d", exc.returncode
            )


def build_cmd(_):
    """Build python packages of production repositories"""
    LOGGER.info("building packages...")
    run_subproc([REPO, 'forall', '-g', 'prod', '-c', 'python3 -m build'])
    LOGGER.info("copying packages to release directory...")
    mkdir(RELEASE_SDIST, RELEASE_WHEEL)
    for repo in enumerate_prod_repositories():
        dist = repo / 'dist'
        try:
            wheel = next(dist.glob('*.whl'))
            wheel.rename(RELEASE_WHEEL / wheel.name)
        except StopIteration:
            LOGGER.warning("could not find wheel for %s", repo)
        try:
            sdist = next(dist.glob('*.tar.gz'))
            sdist.rename(RELEASE_SDIST / sdist.name)
        except StopIteration:
            LOGGER.warning("could not find sdist for %s", repo)


def clean_cmd(_):
    """Remove files produced during build process"""
    LOGGER.info("cleaning up...")
    for repo in enumerate_prod_repositories():
        dist = repo / 'dist'
        if dist.is_dir():
            rmtree(str(dist))
        build = repo / 'build'
        if build.is_dir():
            rmtree(str(build))


def genconf_cmd(_):
    """Generate configuration file from template configuration files"""
    try:
        from ruamel.yaml import load, dump, RoundTripLoader, RoundTripDumper
    except ImportError:
        LOGGER.critical("failed to import YAML from ruamel.yaml!")
        LOGGER.critical(
            "please activate the venv created with 'init' command."
        )
        return
    LOGGER.info("creating configuration file...")
    config = {}
    mkdir(RELEASE)
    for repo in enumerate_prod_repositories():
        LOGGER.debug("processing configuration template in %s", repo)
        try:
            repo_config = next(repo.glob('datashark.dist.yml'))
            with repo_config.open() as fstream:
                merge_conf(config, load(fstream, Loader=RoundTripLoader))
        except StopIteration:
            continue
    output = RELEASE / 'datashark.dist.yml'
    with output.open('w') as fstream:
        dump(config, fstream, Dumper=RoundTripDumper, default_flow_style=False)
    LOGGER.info("full template configuration dumped to %s", output)


def setupdev_cmd(_):
    """Install packages in development mode in virtual environment"""
    dependencies = {}
    # build dependency tree
    for repo in enumerate_prod_repositories():
        config_parser = ConfigParser()
        config_parser.read(str(repo / 'setup.cfg'))
        install_requires = config_parser.get(
            'options', 'install_requires', fallback=''
        )
        dependencies[repo] = {
            dep
            for dep in install_requires.split('\n')
            if dep.startswith('datashark-')
        }
    # resolve dependencies
    ordered_repositories = []
    while dependencies:
        ordered = []
        for repo, reqs in dependencies.items():
            if not reqs:
                ordered.append(repo)
        if not ordered:
            LOGGER.critical("dependency loop detected!")
            return
        for repo in ordered:
            del dependencies[repo]
        for value in dependencies.values():
            for name in [repo.name for repo in ordered]:
                value.discard(name)
        ordered_repositories += ordered
    # install packages
    for repo in ordered_repositories:
        LOGGER.info("installing %s", repo)
        run_subproc(
            [str(PIP), 'install', '--find-links', str(HERE), '-e', str(repo)]
        )


def check_datashark_repo():
    """Check current directory is a datachark repo"""
    if not REPO:
        LOGGER.critical("this script requires 'repo' in the path to run!")
        sys.exit(1)
    manifest = HERE / '.repo' / 'manifests' / 'default.xml'
    if not 'datashark' in manifest.read_text():
        LOGGER.critical("this does not seem to be datashark repo!")
        sys.exit(1)


def setup_command(cmd, name, handler):
    """Setup a command"""
    parser = cmd.add_parser(name, help=handler.__doc__)
    parser.set_defaults(func=handler)
    return parser


def parse_args():
    """Parse command line arguments"""
    parser = ArgumentParser(description="Datashark repo management script")
    parser.add_argument('--debug', '-d', action='store_true')
    cmd = parser.add_subparsers(dest='cmd', help="Command to run")
    cmd.required = True
    setup_command(cmd, 'init', init_cmd)
    setup_command(cmd, 'fmt', fmt_cmd)
    setup_command(cmd, 'lint', lint_cmd)
    setup_command(cmd, 'build', build_cmd)
    setup_command(cmd, 'clean', clean_cmd)
    setup_command(cmd, 'genconf', genconf_cmd)
    setup_command(cmd, 'setupdev', setupdev_cmd)
    return parser.parse_args()


def app():
    """Application entry point"""
    LOGGER.info("running from %s", HERE)
    check_datashark_repo()
    args = parse_args()
    if args.debug:
        LOGGER.setLevel('DEBUG')
    args.func(args)
    LOGGER.info("done.")


if __name__ == '__main__':
    app()
